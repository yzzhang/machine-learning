{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.4.5\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eng.testa', <http.client.HTTPMessage at 0x7efe29c4b898>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.train',\n",
    "           'eng.train')\n",
    "\n",
    "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.testa',\n",
    "           'eng.testa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\n",
      "\n",
      "EU NNP B-NP B-ORG\n",
      "rejects VBZ B-VP O\n",
      "German JJ B-NP B-MISC\n",
      "call NN I-NP O\n",
      "to TO B-VP O\n",
      "boycott VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Peter NNP B-NP B-PER\n",
      "Blackburn NNP I-NP I-PER\n",
      "\n",
      "BRUSSELS NNP B-NP B-LOC\n",
      "1996-08-22 CD I-NP O\n",
      "\n",
      "The DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Commission NNP I-NP I-ORG\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "Thursday NNP B-NP O\n",
      "it PRP B-NP O\n",
      "disagreed VBD B-VP O\n",
      "with IN B-PP O\n",
      "German JJ B-NP B-MISC\n",
      "advice NN I-NP O\n",
      "to TO B-PP O\n",
      "consumers NNS B-NP\n"
     ]
    }
   ],
   "source": [
    "with open(\"eng.train\") as f:\n",
    "    c=f.read()\n",
    "\n",
    "print (c[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14041"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "training_data.show(3)\n",
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "bert_annotator = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
    " .setInputCols([\"sentence\",'token'])\\\n",
    " .setOutputCol(\"bert\")\\\n",
    " .setCaseSensitive(False)\\\n",
    " .setPoolingLayer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|                bert|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
      "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
    "\n",
    "test_data = bert_annotator.transform(test_data)\n",
    "\n",
    "test_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              result|          embeddings|              result|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[cricket, -, leic...|[[-0.1976323, -0....|[O, O, B-ORG, O, ...|\n",
      "|[london, 1996-08-30]|[[0.60744655, 0.2...|          [B-LOC, O]|\n",
      "|[west, indian, al...|[[-0.77769196, -0...|[B-MISC, I-MISC, ...|\n",
      "|[their, stay, on,...|[[-1.0986965, 0.9...|[O, O, O, O, O, O...|\n",
      "|[after, bowling, ...|[[-1.1295222, 0.4...|[O, O, B-ORG, O, ...|\n",
      "|[trailing, by, 21...|[[-1.763109, 0.64...|[O, O, O, O, B-OR...|\n",
      "|[essex, ,, howeve...|[[-0.7097074, -0....|[B-ORG, O, O, O, ...|\n",
      "|[hussain, ,, cons...|[[-0.18262176, 0....|[B-PER, O, O, O, ...|\n",
      "|[by, the, close, ...|[[-0.44396043, 0....|[O, O, O, B-ORG, ...|\n",
      "|[at, the, oval, ,...|[[-1.0189406, -0....|[O, O, B-LOC, O, ...|\n",
      "|[he, was, well, b...|[[-0.48848447, 0....|[O, O, O, O, O, B...|\n",
      "|[derbyshire, kept...|[[-0.08332734, -1...|[B-ORG, O, O, O, ...|\n",
      "|[australian, tom,...|[[0.20087296, 0.3...|[B-MISC, B-PER, I...|\n",
      "|[after, the, frus...|[[-1.1295222, 0.4...|[O, O, O, O, O, O...|\n",
      "|[they, were, held...|[[-1.2368866, 0.7...|[O, O, O, O, O, O...|\n",
      "|[by, stumps, kent...|[[-0.44396043, 0....|[O, O, B-ORG, O, ...|\n",
      "|[cricket, -, engl...|[[-0.1976323, -0....|[O, O, B-MISC, I-...|\n",
      "|[london, 1996-08-30]|[[0.60744655, 0.2...|          [B-LOC, O]|\n",
      "|[result, and, clo...|[[-1.3634797, -0....|[O, O, O, O, O, O...|\n",
      "|[leicester, :, le...|[[-0.21664326, 0....|[B-LOC, O, B-ORG,...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.select(\"bert.result\",\"bert.embeddings\",'label.result').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.1976323 , -0.42026019,  0.55059767, ...,  0.43232313,\n",
       "           0.08174106,  0.20429248],\n",
       "         [-0.95179886,  0.40518612, -0.18066669, ..., -0.56889868,\n",
       "           0.60068387,  0.0411097 ],\n",
       "         [-0.02262329,  0.5078364 ,  0.12273782, ..., -1.2903105 ,\n",
       "          -0.2035525 ,  0.46557245],\n",
       "         ...,\n",
       "         [ 0.05775764, -0.63264298, -0.66510761, ..., -0.70176458,\n",
       "           0.57686883, -0.59081137],\n",
       "         [ 0.26866663, -1.05502069, -0.19403641, ...,  0.30519044,\n",
       "           1.04685092,  0.74213707],\n",
       "         [-0.32736883,  0.54801679,  1.04293954, ...,  0.25098351,\n",
       "           0.55407429,  0.26589558]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "emb_vector = np.array(test_data.select(\"bert.embeddings\").take(1))\n",
    "\n",
    "emb_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.limit(1000).write.parquet(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setLr(0.001)\\\n",
    "  .setPo(0.005)\\\n",
    "  .setBatchSize(8)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(1)\\\n",
    "  .setValidationSplit(0.2)\\\n",
    "  .setEvaluationLogExtended(True) \\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setIncludeConfidence(True)\\\n",
    "  .setTestDataset(\"test_withEmbeds.parquet\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "    bert_annotator,\n",
    "    nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 ms, sys: 20.8 ms, total: 52.6 ms\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ner_model = pipeline.fit(training_data.limit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|                bert|                 ner|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ner_model.transform(test_data)\n",
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|                                  result|                                  result|                                  result|\n",
      "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|[CRICKET, -, LEICESTERSHIRE, TAKE, OV...|   [O, O, B-ORG, O, O, O, O, O, O, O, O]|   [O, O, B-PER, O, O, O, O, O, O, O, O]|\n",
      "|                    [LONDON, 1996-08-30]|                              [B-LOC, O]|                              [B-LOC, O]|\n",
      "|[West, Indian, all-rounder, Phil, Sim...|[B-MISC, I-MISC, O, B-PER, I-PER, O, ...|[B-LOC, O, O, O, B-ORG, O, O, O, O, O...|\n",
      "|[Their, stay, on, top, ,, though, ,, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[After, bowling, Somerset, out, for, ...|[O, O, B-ORG, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[Trailing, by, 213, ,, Somerset, got,...|[O, O, O, O, B-ORG, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[Essex, ,, however, ,, look, certain,...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[Hussain, ,, considered, surplus, to,...|[B-PER, O, O, O, O, B-LOC, O, O, O, O...|[B-PER, O, O, O, O, O, O, O, O, O, O,...|\n",
      "|[By, the, close, Yorkshire, had, turn...|[O, O, O, B-ORG, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[At, the, Oval, ,, Surrey, captain, C...|[O, O, B-LOC, O, B-ORG, O, B-PER, I-P...|[O, O, O, O, O, O, B-PER, I-PER, O, O...|\n",
      "|[He, was, well, backed, by, England, ...|[O, O, O, O, O, B-LOC, O, B-PER, I-PE...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[Derbyshire, kept, up, the, hunt, for...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[Australian, Tom, Moody, took, six, f...|[B-MISC, B-PER, I-PER, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, B-PER, B-PER...|\n",
      "|[After, the, frustration, of, seeing,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
      "|[They, were, held, up, by, a, gritty,...|[O, O, O, O, O, O, O, O, O, B-PER, I-...|[O, O, O, O, O, O, O, O, O, B-PER, B-...|\n",
      "|[By, stumps, Kent, had, reached, 108,...|         [O, O, B-ORG, O, O, O, O, O, O]|         [O, B-LOC, O, O, O, O, O, O, O]|\n",
      "|[CRICKET, -, ENGLISH, COUNTY, CHAMPIO...|    [O, O, B-MISC, I-MISC, I-MISC, O, O]|               [O, O, B-LOC, O, O, O, O]|\n",
      "|                    [LONDON, 1996-08-30]|                              [B-LOC, O]|                              [B-LOC, O]|\n",
      "|[Result, and, close, of, play, scores...|[O, O, O, O, O, O, O, B-MISC, O, O, O...|[O, O, O, O, O, O, O, B-MISC, O, O, O...|\n",
      "|[Leicester, :, Leicestershire, beat, ...|[B-LOC, O, B-ORG, O, B-ORG, O, O, O, ...|[B-ORG, O, B-ORG, O, O, O, O, O, O, O...|\n",
      "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- document: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentence: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- pos: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- label: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- bert: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- ner: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|token         |ground_truth|prediction|\n",
      "+--------------+------------+----------+\n",
      "|CRICKET       |O           |O         |\n",
      "|-             |O           |O         |\n",
      "|LEICESTERSHIRE|B-ORG       |B-PER     |\n",
      "|TAKE          |O           |O         |\n",
      "|OVER          |O           |O         |\n",
      "|AT            |O           |O         |\n",
      "|TOP           |O           |O         |\n",
      "|AFTER         |O           |O         |\n",
      "|INNINGS       |O           |O         |\n",
      "|VICTORY       |O           |O         |\n",
      "|.             |O           |O         |\n",
      "|LONDON        |B-LOC       |B-LOC     |\n",
      "|1996-08-30    |O           |O         |\n",
      "|West          |B-MISC      |B-LOC     |\n",
      "|Indian        |I-MISC      |O         |\n",
      "|all-rounder   |O           |O         |\n",
      "|Phil          |B-PER       |O         |\n",
      "|Simmons       |I-PER       |B-ORG     |\n",
      "|took          |O           |O         |\n",
      "|four          |O           |O         |\n",
      "+--------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>result</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...</td>\n",
       "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, B-PER, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[LONDON, 1996-08-30]</td>\n",
       "      <td>[B-LOC, O]</td>\n",
       "      <td>[B-LOC, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[West, Indian, all-rounder, Phil, Simmons, too...</td>\n",
       "      <td>[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...</td>\n",
       "      <td>[B-LOC, O, O, O, B-ORG, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Their, stay, on, top, ,, though, ,, may, be, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[After, bowling, Somerset, out, for, 83, on, t...</td>\n",
       "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, B-LOC, I...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>[But, the, prices, may, move, in, a, close, ra...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>[Brokers, said, blue, chips, like, IDLC, ,, Ba...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, O, B-ORG, I-ORG, O, B-O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PER, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>[They, said, there, was, still, demand, for, b...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>[The, DSE, all, share, price, index, closed, 2...</td>\n",
       "      <td>[O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>[--, Dhaka, Newsroom, 880-2-506363]</td>\n",
       "      <td>[O, B-ORG, I-ORG, O]</td>\n",
       "      <td>[O, B-LOC, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 result  \\\n",
       "0     [CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...   \n",
       "1                                  [LONDON, 1996-08-30]   \n",
       "2     [West, Indian, all-rounder, Phil, Simmons, too...   \n",
       "3     [Their, stay, on, top, ,, though, ,, may, be, ...   \n",
       "4     [After, bowling, Somerset, out, for, 83, on, t...   \n",
       "...                                                 ...   \n",
       "3245  [But, the, prices, may, move, in, a, close, ra...   \n",
       "3246  [Brokers, said, blue, chips, like, IDLC, ,, Ba...   \n",
       "3247  [They, said, there, was, still, demand, for, b...   \n",
       "3248  [The, DSE, all, share, price, index, closed, 2...   \n",
       "3249                [--, Dhaka, Newsroom, 880-2-506363]   \n",
       "\n",
       "                                                 result  \\\n",
       "0                 [O, O, B-ORG, O, O, O, O, O, O, O, O]   \n",
       "1                                            [B-LOC, O]   \n",
       "2     [B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...   \n",
       "4     [O, O, B-ORG, O, O, O, O, O, O, O, O, B-LOC, I...   \n",
       "...                                                 ...   \n",
       "3245   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3246  [O, O, O, O, O, B-ORG, O, B-ORG, I-ORG, O, B-O...   \n",
       "3247  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3248  [O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "3249                               [O, B-ORG, I-ORG, O]   \n",
       "\n",
       "                                                 result  \n",
       "0                 [O, O, B-PER, O, O, O, O, O, O, O, O]  \n",
       "1                                            [B-LOC, O]  \n",
       "2     [B-LOC, O, O, O, B-ORG, O, O, O, O, O, O, O, O...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "3245   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "3246  [O, O, O, O, O, O, O, O, O, O, B-PER, O, O, O,...  \n",
       "3247  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3248  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3249                                   [O, B-LOC, O, O]  \n",
       "\n",
       "[3250 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = predictions.select('token.result','label.result','ner.result').toPandas()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize_entities_dl download started this may take some time.\n",
      "Approx size to download 159 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "pretrained_pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('Mona', 'B-PER'),\n",
       " ('Lisa', 'I-PER'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('16th', 'O'),\n",
       " ('century', 'O'),\n",
       " ('oil', 'O'),\n",
       " ('painting', 'O'),\n",
       " ('created', 'O'),\n",
       " ('by', 'O'),\n",
       " ('Leonardo', 'B-PER'),\n",
       " ('.', 'O'),\n",
       " (\"It's\", 'O'),\n",
       " ('held', 'O'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Louvre', 'B-LOC'),\n",
       " ('in', 'O'),\n",
       " ('Paris', 'B-LOC'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\n",
    "\n",
    "result = pretrained_pipeline.annotate(text)\n",
    "\n",
    "list(zip(result['token'], result['ner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "def get_ann_pipeline ():\n",
    "    \n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol('document')\n",
    "\n",
    "    sentence = SentenceDetector()\\\n",
    "        .setInputCols(['document'])\\\n",
    "        .setOutputCol('sentence')\\\n",
    "        .setCustomBounds(['\\n'])\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([\"sentence\"]) \\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "    pos = PerceptronModel.pretrained() \\\n",
    "              .setInputCols([\"sentence\", \"token\"]) \\\n",
    "              .setOutputCol(\"pos\")\n",
    "    embeddings = WordEmbeddingsModel.pretrained()\\\n",
    "          .setInputCols([\"sentence\", \"token\"])\\\n",
    "          .setOutputCol(\"embeddings\")\n",
    "\n",
    "    ner_model = NerDLModel.pretrained() \\\n",
    "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "          .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = NerConverter()\\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "      .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "    ner_pipeline = Pipeline(\n",
    "        stages = [\n",
    "            document_assembler,\n",
    "            sentence,\n",
    "            tokenizer,\n",
    "            pos,\n",
    "            embeddings,\n",
    "            ner_model,\n",
    "            ner_converter\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    ner_pipelineFit = ner_pipeline.fit(empty_data)\n",
    "\n",
    "    ner_lp_pipeline = LightPipeline(ner_pipelineFit)\n",
    "\n",
    "    print (\"Spark NLP NER lightpipeline is created\")\n",
    "\n",
    "    return ner_lp_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n",
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n",
      "Spark NLP NER lightpipeline is created\n"
     ]
    }
   ],
   "source": [
    "conll_pipeline = get_ann_pipeline ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': ['Peter Parker is a nice guy and lives in New York.'],\n",
       " 'ner_chunk': ['Peter Parker', 'New York'],\n",
       " 'pos': ['NNP',\n",
       "  'NNP',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'CC',\n",
       "  'NNS',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '.'],\n",
       " 'token': ['Peter',\n",
       "  'Parker',\n",
       "  'is',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'guy',\n",
       "  'and',\n",
       "  'lives',\n",
       "  'in',\n",
       "  'New',\n",
       "  'York',\n",
       "  '.'],\n",
       " 'ner': ['B-PER',\n",
       "  'I-PER',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'O'],\n",
       " 'embeddings': ['Peter',\n",
       "  'Parker',\n",
       "  'is',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'guy',\n",
       "  'and',\n",
       "  'lives',\n",
       "  'in',\n",
       "  'New',\n",
       "  'York',\n",
       "  '.'],\n",
       " 'sentence': ['Peter Parker is a nice guy and lives in New York.']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = conll_pipeline.annotate (\"Peter Parker is a nice guy and lives in New York.\")\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter NNP NNP B-PER\n",
      "Parker NNP NNP I-PER\n",
      "is VBZ VBZ O\n",
      "a DT DT O\n",
      "nice JJ JJ O\n",
      "guy NN NN O\n",
      "and CC CC O\n",
      "lives NNS NNS O\n",
      "in IN IN O\n",
      "New NNP NNP B-LOC\n",
      "York NNP NNP I-LOC\n",
      ". . . O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_lines=''\n",
    "\n",
    "for token, pos, ner in zip(parsed['token'],parsed['pos'],parsed['ner']):\n",
    "\n",
    "    conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, ner)\n",
    "\n",
    "\n",
    "print(conll_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
