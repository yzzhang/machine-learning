{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "interview_attendance.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yzzhang/machine-learning/blob/master/interview_attendance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFA_n4HYbeL5",
        "colab_type": "code",
        "outputId": "0d1ac12f-67b7-4346-9eb7-15b2ca7819e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from   datetime import datetime\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77N8kAuDhFQs",
        "colab_type": "code",
        "outputId": "87d1cc2f-3dfe-460d-944e-e62da48bc8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqKw66XKdQbj",
        "colab_type": "text"
      },
      "source": [
        "Main Goals:\n",
        "\n",
        "\n",
        "\n",
        "1. Create a model predicting if a candidate will attend an interview. This will be indicated by the \"Observed Attendance\" column in the data set. Create the model only using the records where this column is not null\n",
        "\n",
        "2. Provide a probability and a prediction for the candidates where the \"Observed Attendance\" column is null."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glg34AKsbpTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneHotEncodeData(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        This class is to one-hot encode the categorical features.\n",
        "        '''\n",
        "        self.one_hot_feature_names = ['Client name', \n",
        "                        'Industry', \n",
        "                        'Location', \n",
        "                        'Position to be closed', \n",
        "                        'Nature of Skillset',\n",
        "                        'Interview Type', \n",
        "                        #'Name(Cand ID)', \n",
        "                        'Gender', \n",
        "                        'Candidate Current Location',\n",
        "                        'Candidate Job Location', \n",
        "                        'Interview Venue', \n",
        "                        'Candidate Native location',\n",
        "                        'Have you obtained the necessary permission to start at the required time',\n",
        "                        'Hope there will be no unscheduled meetings',\n",
        "                        'Can I Call you three hours before the interview and follow up on your attendance for the interview',\n",
        "                        'Can I have an alternative number/ desk number. I assure you that I will not trouble you too much',\n",
        "                        'Have you taken a printout of your updated resume. Have you read the JD and understood the same',\n",
        "                        'Are you clear with the venue details and the landmark.',\n",
        "                        'Has the call letter been shared', \n",
        "                        'Marital Status']\n",
        "        self.label_encoders   = None\n",
        "        self.one_hot_encoders = None\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        '''\n",
        "        This method trains label encoders and one-hot encoders.\n",
        "        '''\n",
        "        \n",
        "        X1 = X.copy()\n",
        "        \n",
        "        # one_hot_features = np.zeros((feature_values.shape[0], 0))\n",
        "\n",
        "        label_encoders   = {}\n",
        "        one_hot_encoders = {}\n",
        "        for fname in self.one_hot_feature_names:\n",
        "            label_encoder   = LabelEncoder()\n",
        "            one_hot_encoder = OneHotEncoder(categories='auto')\n",
        "            feature         = X1[fname]\n",
        "            feature_label_encoded = label_encoder.fit_transform(feature)\n",
        "            label_encoders[fname]   = label_encoder;\n",
        "            one_hot_encoder.fit(feature_label_encoded.reshape(-1,1))\n",
        "            one_hot_encoders[fname] = one_hot_encoder;\n",
        "        \n",
        "        # save label encoders and one-hot encoders for encoding test dataset later on\n",
        "        self.label_encoders   = label_encoders\n",
        "        self.one_hot_encoders = one_hot_encoders\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        '''\n",
        "        This method uses trained label encoders and one-hot encoders \n",
        "        to one-hot encodes the given catogrical fields.\n",
        "        '''   \n",
        "        X1 = X.copy()\n",
        "        \n",
        "        # one-hot encode\n",
        "        one_hot_features = np.zeros((X1.shape[0], 0))\n",
        "        for fname in self.one_hot_feature_names:\n",
        "            label_encoder   = self.label_encoders[fname]\n",
        "            one_hot_encoder = self.one_hot_encoders[fname]\n",
        "            feature  = X1[fname]\n",
        "            fencoded = label_encoder.transform(feature)\n",
        "            f1hot    = one_hot_encoder.transform(fencoded.reshape(-1,1)).toarray()\n",
        "            one_hot_features = np.c_[one_hot_features, f1hot] \n",
        "        \n",
        "        # drop the original features that have just been one-hot encoded\n",
        "        X1 = pd.DataFrame(X1).drop(self.one_hot_feature_names, axis=1).values\n",
        "        \n",
        "        # combine one-hot codes into the features array\n",
        "        X1 = np.c_[X1, one_hot_features]\n",
        "\n",
        "        return X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2N0ZOB3d8mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeaturesUppercase(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feature_names, drop_feature_names):\n",
        "        '''\n",
        "        This class is to change feature values to uppercase.\n",
        "        '''\n",
        "        self.feature_names      = feature_names\n",
        "        self.drop_feature_names = drop_feature_names\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "        \n",
        "    def transform(self, X, y=None):\n",
        "        '''\n",
        "        This method is to change feature values to uppercase.\n",
        "        '''\n",
        "        X_uppercase = X.copy()\n",
        "        \n",
        "        for fname in self.feature_names:\n",
        "            values = X_uppercase[fname]\n",
        "            values = values.fillna('NaN')\n",
        "            values = map(lambda x: x.strip().upper(), values)\n",
        "            X_uppercase[fname] = values\n",
        "        \n",
        "        # drop less important features\n",
        "        X_uppercase = X_uppercase.drop(self.drop_feature_names, axis=1)\n",
        "            \n",
        "        return X_uppercase   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdbU3ZTTeHXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParseInterviewDate(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        This class is to splits the date of interview into day (2 digits), month (2 digits), year (4 digits).\n",
        "        '''     \n",
        "    def __parseDate(self, string, delimit):\n",
        "        try:\n",
        "            if ('&' in string):\n",
        "                subs = tuple(string.split('&'))\n",
        "                string = subs[0]\n",
        "        except:\n",
        "            print ('TypeError: {}'.format(string))\n",
        "            return None\n",
        "        \n",
        "        string = string.strip()\n",
        "        \n",
        "        try:\n",
        "            d = datetime.strptime(string, '%d{0}%m{0}%Y'.format(delimit))\n",
        "        except:\n",
        "            try:\n",
        "                d = datetime.strptime(string, '%d{0}%m{0}%y'.format(delimit))\n",
        "            except:\n",
        "                try:\n",
        "                     d = datetime.strptime(string, '%d{0}%b{0}%Y'.format(delimit))\n",
        "                except:\n",
        "                    try:\n",
        "                         d = datetime.strptime(string, '%d{0}%b{0}%y'.format(delimit))\n",
        "                    except:\n",
        "                        try:\n",
        "                            d = datetime.strptime(string, '%b{0}%d{0}%Y'.format(delimit))\n",
        "                        except:\n",
        "                            try:\n",
        "                                d = datetime.strptime(string, '%b{0}%d{0}%y'.format(delimit))\n",
        "                            except:\n",
        "                                d = None\n",
        "        return d\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        '''\n",
        "        This method splits the date of interview into day (2 digits), month (2 digits), year (4 digits).\n",
        "        '''\n",
        "        \n",
        "        X1 = X.copy()\n",
        "        \n",
        "        days = []\n",
        "        months = []\n",
        "        years = []\n",
        "        ditems = X1['Date of Interview'].values\n",
        "        for ditem in ditems:\n",
        "            if (isinstance(ditem, str) and len(ditem) > 0):\n",
        "                if ('.' in ditem):\n",
        "                    d = self.__parseDate(ditem, '.')\n",
        "                elif ('/' in ditem):\n",
        "                    d = self.__parseDate(ditem, '/')\n",
        "                elif ('-' in ditem):\n",
        "                    d = self.__parseDate(ditem, '-')\n",
        "                elif (' ' in ditem):\n",
        "                    d = self.__parseDate(ditem, ' ')\n",
        "                else:\n",
        "                    d = None\n",
        "                    \n",
        "                if (d is None):\n",
        "                    # print(\"{}, invalid format of interview date!\".format(ditem))\n",
        "                    days.append(0) # 0 - NaN\n",
        "                    months.append(0)\n",
        "                    years.append(0)\n",
        "                else:\n",
        "                    days.append(d.day) \n",
        "                    months.append(d.month)\n",
        "                    years.append(d.year)\n",
        "            else:\n",
        "                days.append(0)\n",
        "                months.append(0)\n",
        "                years.append(0)\n",
        "        \n",
        "        X1['Year'] = years\n",
        "        X1['Month'] = months\n",
        "        X1['Day'] = days\n",
        "         \n",
        "        return X1   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKyE5zV4eSZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BucketSkillset(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        This class is to re-bucket the skill sets and candidates location features \n",
        "        to combine small catogaries into one catogary 'Others'.\n",
        "        '''\n",
        "        self.skillset = ['JAVA/J2EE/Struts/Hibernate', 'Fresher', 'Accounting Operations', 'CDD KYC', 'Routine', 'Oracle', \n",
        "          'JAVA/SPRING/HIBERNATE/JSF', 'Java J2EE', 'SAS', 'Oracle Plsql', 'Java Developer', \n",
        "          'Lending and Liabilities', 'Banking Operations', 'Java', 'Core Java', 'Java J2ee', 'T-24 developer', \n",
        "          'Senior software engineer-Mednet', 'ALS Testing', 'SCCM', 'COTS Developer', 'Analytical R & D', \n",
        "          'Sr Automation Testing', 'Regulatory', 'Hadoop', 'testing', 'Java', 'ETL', 'Publishing']\n",
        "        \n",
        "        self.candidate_locations = ['Chennai', 'Hyderabad', 'Bangalore', 'Gurgaon', 'Cuttack', 'Cochin', \n",
        "                          'Pune', 'Coimbatore', 'Allahabad', 'Noida', 'Visakapatinam', 'Nagercoil',\n",
        "                          'Trivandrum', 'Kolkata', 'Trichy', 'Vellore']\n",
        "        \n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        '''\n",
        "        This method is to re-bucket the skill sets and candidates native locations features.\n",
        "        '''\n",
        "            \n",
        "        X1 = X.copy()\n",
        "        \n",
        "        fnames = ('Nature of Skillset', 'Candidate Native location')\n",
        "        fset   = (self.skillset, self.candidate_locations)\n",
        "        for i, fname in enumerate(fnames):\n",
        "            fvalues = X1[fname]\n",
        "            X2 = map(lambda x: x if x in fset[i] else 'Others', fvalues)\n",
        "            X1[fname] = pd.Series(X2)\n",
        "            \n",
        "        return X1  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN6TnUV8eaSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GridSearch(object):\n",
        "    def __init__(self, cv=10):\n",
        "        '''\n",
        "        This class finds the best model via Grid Search.\n",
        "        '''\n",
        "        self.grid_param = [\n",
        "            {'n_estimators': range(68,69), # range(60, 70) # best 68\n",
        "             'max_depth'   : range(8,9)}   # range(5, 10)}  # best 8\n",
        "        ]\n",
        "        self.cv = cv\n",
        "        self.scoring_function = make_scorer(f1_score, greater_is_better=True) \n",
        "        self.gridSearch = None\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        rfc = RandomForestClassifier()\n",
        "        self.gridSearch = GridSearchCV(rfc, self.grid_param, cv=self.cv, scoring=self.scoring_function)\n",
        "        self.gridSearch.fit(X, y)\n",
        "        return self.gridSearch.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9I-2iIeehfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictInterview(object):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        This class is to predict the probability of a candidate attending scheduled interviews.\n",
        "        '''\n",
        "        self.dataset_file_name = 'Interview_Attendance_Data.csv'\n",
        "        self.feature_names = ['Date of Interview', \n",
        "                       'Client name', \n",
        "                       'Industry', \n",
        "                       'Location', \n",
        "                       'Position to be closed', \n",
        "                       'Nature of Skillset',\n",
        "                       'Interview Type', \n",
        "                       #'Name(Cand ID)',\n",
        "                       'Gender', \n",
        "                       'Candidate Current Location',\n",
        "                       'Candidate Job Location', \n",
        "                       'Interview Venue', \n",
        "                       'Candidate Native location',\n",
        "                       'Have you obtained the necessary permission to start at the required time',\n",
        "                       'Hope there will be no unscheduled meetings',\n",
        "                       'Can I Call you three hours before the interview and follow up on your attendance for the interview',\n",
        "                       'Can I have an alternative number/ desk number. I assure you that I will not trouble you too much',\n",
        "                       'Have you taken a printout of your updated resume. Have you read the JD and understood the same',\n",
        "                       'Are you clear with the venue details and the landmark.',\n",
        "                       'Has the call letter been shared', 'Marital Status']\n",
        "        \n",
        "        self.drop_feature_names = [\n",
        "                        'Name(Cand ID)',\n",
        "                        'Date of Interview', \n",
        "                        'Unnamed: 22', \n",
        "                        'Unnamed: 23', \n",
        "                        'Unnamed: 24', \n",
        "                        'Unnamed: 25', \n",
        "                        'Unnamed: 26']\n",
        "        \n",
        "        self.dataset = None\n",
        "        self.rfc     = None\n",
        "        self.gridSearch = None\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.X_test  = None\n",
        "        self.y_test  = None\n",
        "        self.y_pred  = None\n",
        "        self.X_clean = None\n",
        "        self.y_clean = None\n",
        "        self.X_train_encoded = None\n",
        "        self.X_test_encoded  = None\n",
        "        self.y_train_encoded = None\n",
        "        self.accuracy_score  = None \n",
        "        self.f1_score        = None\n",
        "        self.oneHotEncoder   = None\n",
        "        self.X_test_name_ids = None\n",
        "        self.pipeline = None\n",
        "        \n",
        "        \n",
        "    def loadData(self, path=None):\n",
        "        '''\n",
        "        This method loads a dataset file as a Pandas DataFrame, assuming that the dataset file is in csv format.\n",
        "        It also shuffles the loaded dataset as part of data preprocessing.\n",
        "        '''\n",
        "        if (path != None):\n",
        "            path = os.path.join(path, self.dataset_file_name)\n",
        "        else:\n",
        "            path = self.dataset_file_name\n",
        "            \n",
        "        dataset = pd.read_csv(path)\n",
        "        \n",
        "        # shuffle data \n",
        "        self.dataset = dataset.sample(frac=1).reset_index(drop=True) \n",
        "        \n",
        "        return self.dataset     \n",
        "    \n",
        "    def PreprocessData(self):\n",
        "        '''\n",
        "        This method preprocesses the loaded dataset before applying one-hot encoding.\n",
        "        '''\n",
        "            \n",
        "        y = self.dataset['Observed Attendance']                # extract labels y\n",
        "        X = self.dataset.drop(['Observed Attendance'], axis=1) # extract features X\n",
        "        \n",
        "        self.oneHotEncoder = OneHotEncodeData()\n",
        "        \n",
        "        self.pipeline = Pipeline([\n",
        "            ('bucket_skillset', BucketSkillset()),\n",
        "            ('parse_interview_date', ParseInterviewDate()),\n",
        "            ('features_to_uppercase', FeaturesUppercase(self.feature_names, self.drop_feature_names)),\n",
        "            ('one_hot_encoder', self.oneHotEncoder)\n",
        "        ])\n",
        "        \n",
        "        X_1hot = self.pipeline.fit_transform(X)\n",
        "        \n",
        "        # fill up missing labels and then change labels to uppercase\n",
        "        y = y.fillna('NaN')\n",
        "        y_uppercase = map(lambda x: x.strip().upper(), y.values)\n",
        "        y_uppercase = pd.Series(y_uppercase)\n",
        "        \n",
        "        # separate labeled records from unlabeled records\n",
        "        self.X_train_encoded = X_1hot[y_uppercase != 'NAN']\n",
        "        self.X_test_encoded  = X_1hot[y_uppercase == 'NAN']\n",
        "        \n",
        "        # save Names/ID for reporting later one\n",
        "        self.X_test_name_ids = self.dataset['Name(Cand ID)'][y_uppercase == 'NAN']\n",
        "        \n",
        "        y_train = y_uppercase[y_uppercase != 'NAN']\n",
        "        # encode labels as follows: 0 - NO, 1 - YES, NAN - NAN\n",
        "        y = map(lambda x: 1 if x == 'YES' else 0, y_train)\n",
        "        y = pd.Series(y)\n",
        "        \n",
        "        self.y_train_encoded = y.values\n",
        "        \n",
        "        self.X_clean = X_1hot\n",
        "        self.y_clean = y_uppercase\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def __splitData(self):\n",
        "        '''\n",
        "        This method triggers data preprocsssing and split dataset into training and testing datasets.\n",
        "        '''\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X_train_encoded, \n",
        "                                                                                self.y_train_encoded, \n",
        "                                                                                test_size = 0.25, random_state = 0)\n",
        "        return (self.X_train, self.X_test, self.y_train, self.y_test)\n",
        "    \n",
        "    def trainModel(self):\n",
        "        '''\n",
        "        This method triggers splitting dataset and then find a best RandomForest model via grid search \n",
        "        using the training features and labels.\n",
        "        '''\n",
        "        X_train, X_test, y_train, y_test = self.__splitData()\n",
        "        self.gridSearch = GridSearch()\n",
        "        self.rfc = self.gridSearch.fit(X_train, y_train)\n",
        "        return self.rfc\n",
        "    \n",
        "    def predictClasses(self):\n",
        "        '''\n",
        "        This method predicts classes (YES or NO) using a trained model.\n",
        "        '''\n",
        "        if (self.rfc is None):\n",
        "            print(\"No trained model available, please train a model first!\")\n",
        "            return None\n",
        "        \n",
        "        self.y_pred = self.rfc.predict(self.X_test)\n",
        "        return self.y_pred\n",
        "    \n",
        "    def getModelMetrics(self):\n",
        "        '''\n",
        "        This method obtains the class prediction scores: (Accuracy Score, R2, F1).\n",
        "        '''\n",
        "        if (self.y_test is None or self.y_pred is None):\n",
        "            print('Failed to get model performance metrics because y_test is null or y_pred is null!')\n",
        "            return None\n",
        "        \n",
        "        self.accuracy_score = accuracy_score(self.y_test, self.y_pred)\n",
        "        self.f1_score = f1_score(self.y_test, self.y_pred)\n",
        "        \n",
        "        return (self.accuracy_score, self.f1_score)\n",
        "    \n",
        "    def predictNullAttendanceProbability(self):\n",
        "        '''\n",
        "        This method uses a trained model to predict the attendance probability for \n",
        "        the candidates where the \"Observed Attendance\" column is null.\n",
        "        '''\n",
        "        y_pred = self.rfc.predict_proba(self.X_test_encoded)\n",
        "        return y_pred\n",
        "    \n",
        "    def predictNullAttendanceClasses(self):\n",
        "        '''\n",
        "        This method predicts classes (YES or NO) using a trained model for unlabeled data records.\n",
        "        '''\n",
        "        y_pred = self.rfc.predict(self.X_test_encoded)\n",
        "        return y_pred\n",
        "    \n",
        "    def predictAttendanceProbability(self, X):\n",
        "        '''\n",
        "        Given one preprocessed (including one-hot encoding) data smaple X,\n",
        "        this method returns the probability of attendance probability.\n",
        "        '''\n",
        "        y_pred = self.rfc.predict_proba(X)\n",
        "        return y_pred\n",
        "    \n",
        "    def predictAttendanceClass(self, X):\n",
        "        '''\n",
        "        Given one preprocessed (including one-hot encoding) data smaple X,\n",
        "        this method returns the attendance Yes/No.\n",
        "        '''\n",
        "        y_pred = self.rfc.predict(X)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGJCZPyCeuiZ",
        "colab_type": "text"
      },
      "source": [
        "Task 1 \n",
        "\n",
        "(a) Create a model predicting if a candidate will attend an interview. This will be indicated by the \"Observed Attendance\" column in the data set. Create the model only using the records where this column is not null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cn6g-Xgeoz5",
        "colab_type": "code",
        "outputId": "27d2f6f7-9739-4eb8-ff0c-2b7c1b357219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictInterview = PredictInterview()\n",
        "predictInterview.loadData()\n",
        "predictInterview.PreprocessData()\n",
        "predictInterview.trainModel()\n",
        "predictInterview.predictClasses()\n",
        "accuracy_score, f1_score = predictInterview.getModelMetrics()\n",
        "\n",
        "print('accuracy score = {0}, F1 score = {1}'.format(accuracy_score, f1_score))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score = 0.6070175438596491, F1 score = 0.7383177570093459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxLwNNKfA8J",
        "colab_type": "text"
      },
      "source": [
        "Task 1 \n",
        "\n",
        "(b) Provide a probability and a prediction for the candidates where the \"Observed Attendance\" column is null."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xVjeQ9jfKTO",
        "colab_type": "code",
        "outputId": "14deea46-68de-4e14-883c-0a8238c74128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pred_probs   = predictInterview.predictNullAttendanceProbability()\n",
        "pred_classes = predictInterview.predictNullAttendanceClasses()\n",
        "\n",
        "x = predictInterview.X_test_name_ids \n",
        "z = zip(x, pred_probs, pred_classes)\n",
        "answers = ('no', 'yes')\n",
        "\n",
        "result = [[x1, p1[1], answers[c]] for x1, p1, c in z]\n",
        "result_df = pd.DataFrame(np.array(result), columns=['Names/ID', 'Probability', 'Yes/No'])\n",
        "result_df.to_csv('interview_prediction.csv')\n",
        "result_df.head(100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names/ID</th>\n",
              "      <th>Probability</th>\n",
              "      <th>Yes/No</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Candidate 493</td>\n",
              "      <td>0.6120170242861639</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Candidate 412</td>\n",
              "      <td>0.6628306752784917</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Candidate 889</td>\n",
              "      <td>0.8054671590993251</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Candidate 332</td>\n",
              "      <td>0.5566438704078654</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Candidate 1156</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Candidate 706</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Candidate 1171</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Candidate 271</td>\n",
              "      <td>0.6061535945365052</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Candidate 30</td>\n",
              "      <td>0.37702282476774496</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Candidate 427</td>\n",
              "      <td>0.6288211582302367</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Candidate 631</td>\n",
              "      <td>0.6261722851704755</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Candidate 150</td>\n",
              "      <td>0.7193069404978832</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Candidate 829</td>\n",
              "      <td>0.5697057016050596</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Candidate 751</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Candidate 1222</td>\n",
              "      <td>0.8055448185253136</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Candidate 982</td>\n",
              "      <td>0.6585726564304033</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Candidate 300</td>\n",
              "      <td>0.6061535945365052</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Candidate 796</td>\n",
              "      <td>0.4060395022814813</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Candidate 160</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>nan</td>\n",
              "      <td>0.046434738889981855</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Candidate 90</td>\n",
              "      <td>0.7166126087270666</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Candidate 676</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Candidate 40</td>\n",
              "      <td>0.5034678652133209</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Candidate 290</td>\n",
              "      <td>0.6061535945365052</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Candidate 1189</td>\n",
              "      <td>0.49263046175925806</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Candidate 220</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Candidate 919</td>\n",
              "      <td>0.31480786751774165</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Candidate 553</td>\n",
              "      <td>0.6714788170715104</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Candidate 781</td>\n",
              "      <td>0.6205289892032649</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Candidate 646</td>\n",
              "      <td>0.4814586163860426</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Candidate 180</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Candidate 871</td>\n",
              "      <td>0.6205289892032649</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Candidate 1000</td>\n",
              "      <td>0.9455701285883047</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Candidate 80</td>\n",
              "      <td>0.7166126087270666</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Candidate 904</td>\n",
              "      <td>0.31480786751774165</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Candidate 1207</td>\n",
              "      <td>0.49263046175925806</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>Candidate 230</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Candidate 140</td>\n",
              "      <td>0.7193069404978832</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Candidate 50</td>\n",
              "      <td>0.7166126087270666</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Candidate 583</td>\n",
              "      <td>0.6714788170715104</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Candidate 100</td>\n",
              "      <td>0.7193069404978832</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Candidate 1123</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Candidate 1108</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Candidate 1093</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Candidate 721</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Candidate 1033</td>\n",
              "      <td>0.6359839838024991</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Candidate 736</td>\n",
              "      <td>0.6709684922247785</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Candidate 1233</td>\n",
              "      <td>0.8969794174492731</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Candidate 210</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>Candidate 20</td>\n",
              "      <td>0.5104479091490404</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Candidate 523</td>\n",
              "      <td>0.7142814605994391</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Candidate 478</td>\n",
              "      <td>0.6120170242861639</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Candidate 598</td>\n",
              "      <td>0.5994306755336168</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Candidate 120</td>\n",
              "      <td>0.7193069404978832</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Candidate 240</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Candidate 200</td>\n",
              "      <td>0.6758743785224711</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Candidate 451</td>\n",
              "      <td>0.8055448185253136</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Candidate 1048</td>\n",
              "      <td>0.7589630906419673</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Candidate 10</td>\n",
              "      <td>0.5756895255823675</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Candidate 1063</td>\n",
              "      <td>0.7589630906419673</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Names/ID           Probability Yes/No\n",
              "0    Candidate 493    0.6120170242861639    yes\n",
              "1    Candidate 412    0.6628306752784917    yes\n",
              "2    Candidate 889    0.8054671590993251    yes\n",
              "3    Candidate 332    0.5566438704078654    yes\n",
              "4   Candidate 1156    0.6709684922247785    yes\n",
              "5    Candidate 706    0.6709684922247785    yes\n",
              "6   Candidate 1171    0.6709684922247785    yes\n",
              "7    Candidate 271    0.6061535945365052    yes\n",
              "8     Candidate 30   0.37702282476774496     no\n",
              "9    Candidate 427    0.6288211582302367    yes\n",
              "10   Candidate 631    0.6261722851704755    yes\n",
              "11   Candidate 150    0.7193069404978832    yes\n",
              "12   Candidate 829    0.5697057016050596    yes\n",
              "13   Candidate 751    0.6709684922247785    yes\n",
              "14  Candidate 1222    0.8055448185253136    yes\n",
              "15   Candidate 982    0.6585726564304033    yes\n",
              "16   Candidate 300    0.6061535945365052    yes\n",
              "17   Candidate 796    0.4060395022814813     no\n",
              "18   Candidate 160    0.6758743785224711    yes\n",
              "19             nan  0.046434738889981855     no\n",
              "20    Candidate 90    0.7166126087270666    yes\n",
              "21   Candidate 676    0.6709684922247785    yes\n",
              "22    Candidate 40    0.5034678652133209    yes\n",
              "23   Candidate 290    0.6061535945365052    yes\n",
              "24  Candidate 1189   0.49263046175925806     no\n",
              "25   Candidate 220    0.6758743785224711    yes\n",
              "26   Candidate 919   0.31480786751774165     no\n",
              "27   Candidate 553    0.6714788170715104    yes\n",
              "28   Candidate 781    0.6205289892032649    yes\n",
              "29   Candidate 646    0.4814586163860426     no\n",
              "..             ...                   ...    ...\n",
              "64   Candidate 180    0.6758743785224711    yes\n",
              "65   Candidate 871    0.6205289892032649    yes\n",
              "66  Candidate 1000    0.9455701285883047    yes\n",
              "67    Candidate 80    0.7166126087270666    yes\n",
              "68   Candidate 904   0.31480786751774165     no\n",
              "69  Candidate 1207   0.49263046175925806     no\n",
              "70   Candidate 230    0.6758743785224711    yes\n",
              "71   Candidate 140    0.7193069404978832    yes\n",
              "72    Candidate 50    0.7166126087270666    yes\n",
              "73   Candidate 583    0.6714788170715104    yes\n",
              "74   Candidate 100    0.7193069404978832    yes\n",
              "75  Candidate 1123    0.6709684922247785    yes\n",
              "76  Candidate 1108    0.6709684922247785    yes\n",
              "77  Candidate 1093    0.6709684922247785    yes\n",
              "78   Candidate 721    0.6709684922247785    yes\n",
              "79  Candidate 1033    0.6359839838024991    yes\n",
              "80   Candidate 736    0.6709684922247785    yes\n",
              "81  Candidate 1233    0.8969794174492731    yes\n",
              "82   Candidate 210    0.6758743785224711    yes\n",
              "83    Candidate 20    0.5104479091490404    yes\n",
              "84   Candidate 523    0.7142814605994391    yes\n",
              "85   Candidate 478    0.6120170242861639    yes\n",
              "86   Candidate 598    0.5994306755336168    yes\n",
              "87   Candidate 120    0.7193069404978832    yes\n",
              "88   Candidate 240    0.6758743785224711    yes\n",
              "89   Candidate 200    0.6758743785224711    yes\n",
              "90   Candidate 451    0.8055448185253136    yes\n",
              "91  Candidate 1048    0.7589630906419673    yes\n",
              "92    Candidate 10    0.5756895255823675    yes\n",
              "93  Candidate 1063    0.7589630906419673    yes\n",
              "\n",
              "[94 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}